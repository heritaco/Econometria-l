---
title: "Practica 2"
author: "Agustin Riquelme y Heriberto Espino"
date: "2023-09-06"
output: html_document
---

</n>

Con el objetivo de sintetizar las líneas de código lo más posible, se ha creado una función que requerirá como argumentos la variable de respuesta y la variable predictora para el modelo, así como el nivel de significancia α. Esta función se utilizará a lo largo del presente documento. Con el fin de visualizar los datos de manera más amigable, el código de la función se ocultará en el informe, pero se mantendrá en formato markdown para su correcta ejecución.

```{r echo = FALSE, warning = FALSE}

library(DT)
library(kableExtra)
library(readr)


basic <- c("stripped", "boarded", "hover", "condensed", "responsive")
data <- read_csv("C:/Users/herie/OneDrive - Fundacion Universidad de las Americas Puebla/Semestre/5 Semestre/Econometria l/Advertising.csv", 
                 col_types = cols(.default = col_double()))

tv    <- data$TV
radio <- data$radio
newsp <- data$newspaper
sales <- data$sales

```


```{r echo = FALSE, fig.align = "center"}
linealmodel <-   function(x, y, α){
  modelo <- lm(y ~ x)
  d <- c()
  e <- c("β0","β1","S","S cuad", "cv", "df","qti","qtd","tc","p value","Int. conf.","","Prom. err.", "Var. err.","P. Hip. β1 Est.","P. Hip. β1 Pvalue","Rho")
  # Plot
    boxplot(x, col = "lightblue1", xlab = "Variable de predictora", main = "Boxplot x")
    hist(x, col = "darkseagreen1", xlab = "Variable de predictora", main = "Histograma x", breaks = 20)
    plot(x,y, col = "coral1", xlab = "Variable de predictora", ylab = "Variable de respuesta", main = "Gráfico dispersión")
    plot(x, y, col = "#761E1E", pch = 16, lwd = 1,  cex = 0.5,
           xlab = "Variable predictora", ylab = "Variable de respuesta", main = "Recta de regresión",
           abline( lm( y ~ x ), col = "#bc4749", lwd = 3) )
  # Identificar cosas
          n <- length(x)
          SCx <- 1
          SCy <- 2
          SCxy <- 3
        # Identificar β0
          β0 <- modelo$coefficients["(Intercept)"]
          d[1] <- β0
        # Identificar β1
          β1 <- modelo$coefficients["x"]
          d[2] <- β1
        # Ecuación de la recta
          yhat = recta <- β0  +  β1 * x
        # s
          s <- modelo$sigma
          d[3] <- s
        # S cuad
          scuad <- s^2
          d[4] <- s^2
        # Coef de correlacion
          rho <- sqrt(modelo$r.squared)
          d[17] <- rho
        # CV
          cv <- 100 * s / mean(x)
          d[5] <- cv
  # Inferencia para β1# H0: β1 = 0 vs H1: β1 ≠ 0
        # Obtener df
          df <- modelo$df[2]
          d[6] <- df
        # Obtener las qt
          qti <- qt(α/2, df, lower.tail = TRUE)
          d[7] <- qti
          qtd <- qt(α/2, df, lower.tail = FALSE)
          d[8] <- qtd
        # Obtener tc
          tc <- modelo$coefficients["x", "t value"]
          d[9] <- tc
        # Obtener pvalor
          pvalor <- modelo$coefficients["x", "Pr(>|t|)"]
          d[10] <- pvalor
        # Prueba de hipotesis para β1
          if( abs(tc) > qtd ){
            d[15] = "Rechazamos H0"
          }else{
            d[15] = "No rechazamos H0"
          }
          if( pvalor < α){
            d[16] = "Rechazamos H0"
          }else{
            d[16] = "No rechazamos H0"
          }
  # Intervalo de confianza para β1
          intconfβ1 <- confint(modelo, level = 1 - α)
          intconfβ1 <- intconfβ1["x", ]
          d[11] <- intconfβ1[1]
          d[12] <- intconfβ1[2]
  # Error estándar de yhat (intervalos de confianza )
        erroryprom <- s * sqrt( (1/n)  +  (x - mean(x))^2 / (sum(x^2)  -  n * mean(x)^2  ) ) 
        errorpredic <- s * sqrt( 1  +  (1/n)  +  (x - mean(x))^2 / (sum(x^2)  -  n * mean(x)^2) ) 
        # Límite inferior error estándar del promedio de y
          lieeyprom <- recta  -  qtd * erroryprom
        # Límite superior error estándar del promedio de y
          lseeyprom <- recta  +  qtd * erroryprom
        # Límite inferior del error estándar de la predicción
          lieepredic <- recta  -  qtd * errorpredic
        # Límite superior del error estándar de la predicción
          lseepredic <- recta  +  qtd * errorpredic
        # Gráfica
          plot(x, y, col = "#3b1f2b", lwd = .5, pch = 16, cex = 0.5,
               xlab = "x", ylab = "y", main = "Intervalos de confianza")
                abline (a = β0, b = β1, col = "#ff5a5f", lwd = 2)
                lines (x = sort(x),  y = sort(lieeyprom),  col="#ff4d00",  lty = 2, lwd = 2)
                lines (x = sort(x),  y = sort(lseeyprom),  col="#ff4d00",  lty = 2, lwd = 2)
                lines (x = sort(x),  y = sort(lieepredic),  col="#ffd100",  lty = 2, lwd = 2)
                lines (x = sort(x),  y = sort(lseepredic),  col="#ffd100",  lty = 2, lwd = 2)
  # Análisis de residudales
          error <- y - recta
          d[13] <- mean(abs(error))
          d[14] <- var(abs(error))
        # Gráfica para saber si es varianza fija
          plot(error, col="#0d47a1", type = "o",lwd = 2, pch = 16,
               xlab = "Índice de Observación", ylab = "Valor de Error", main = "Gráfico de Errores")
            lines(1:n, rep(0,n), col="#df3e3e", lwd = 2)
        # Histograma
          hist(error, col = "#415a77", border = "white",
               main = "Histograma de Errores", xlab = "Errores", ylab = "Frecuencia")
        # Boxplot
          boxplot(error, main = "Boxplot", col = "#588157", medcol = "#344e41", border = "#344e41")
        # QQ
          qqnorm(error, col = "#ad2831", lwd = 2, pch = 0, cex = 0.1,
                 main = "Gráfico QQ de Errores", xlab = "Cuantiles teóricos", ylab = "Cuantiles de los errores") 
                 qqline(error, col = "#640d14", lwd = 2)
          data.frame("Datos" = e, "Valores" = d) %>%
          kbl(caption = "Informacion del modelo") %>%
          kable_classic(bootstrap_options = basic, full_width = F, html_font = "Cambria")
          tabla_contingencia <- table(x, y)

          
      # Normalidad
        library(nortest)
        normalidad_anderson <- ad.test(error) 
        normalidad_anderson
          if (normalidad_anderson$p.value >= α) {
            cat("Como el pvalor ≥ α, no rechazamos H0(los datos son normales),
                  y no hay evidencia que garantice que NO son normales\n",
                normalidad_anderson$p.value, "≥", α)
          } else {
            cat("Como el pvalor < α, rechazamos H0, los datos NO son normales\n", 
                normalidad_anderson$p.value, "<", α)
          }
        
        
        # Lilline # 
        normalidad_lilline <- lillie.test(error)
        normalidad_lilline
          if (normalidad_lilline$p.value >= α) {
            cat("Como el pvalor ≥ α, no rechazamos H0(los datos son normales),
                  y no hay evidencia que garantice que NO son normales\n",
                normalidad_lilline$p.value, "≥", α)
          } else {
            cat("Como el pvalor < α, rechazamos H0, los datos NO son normales\n", 
                normalidad_lilline$p.value, "<", α)
          }

        
      # Correlacion
        # Pearson #
        correlacion_pearson <- cor(x, y)
          
          if (abs(correlacion_pearson) >= 0.6) {
            mensaje <- "Hay una correlación fuerte,"
          } else if (abs(correlacion_pearson) <= 0.4) {
            mensaje <- "Hay una correlación baja,"
          } else {
            mensaje <- "Hay una correlación media,"
          }
          
          cat(mensaje, "coeficiente de correlación de Pearson:", correlacion_pearson)
        
        
        # Spearman #
        correlacion_spearman <- cor(x, y, method = "spearman")
        
          if (abs(correlacion_spearman) >= 0.6) {
            mensaje <- "Hay una correlación fuerte,"
          } else if (abs(correlacion_spearman) <= 0.4) {
            mensaje <- "Hay una correlación baja,"
          } else {
            mensaje <- "Hay una correlación media,"
          }
          
          cat(mensaje, "coeficiente de correlación de Spearman:", correlacion_spearman)
            }
```



A continuación se presentarán los resultados obtenidos para cada modelo de regresión lineal simple. En estos análisis, la variable "sales" se considera como la variable de respuesta, mientras que los gastos de marketing en cada una de las plataformas se tratan como las variables predictoras. Esto se debe a que las ventas pueden estar relacionadas con el medio a través del cual se realiza el marketing. En este contexto, podemos utilizar estos modelos para predecir las ventas en función de una campaña de marketing ya propuesta y determinar si es óptima o no.

Para el modelo de regresión que involucra las ventas y el marketing en televisión, los resultados son los siguientes:

```{r}
linealmodel(tv, sales, 0.05)
```

Las tres primeras gráficas representan nuestro vector que almacena todos los presupuestos publicitarios (en miles de dólares) para televisión. Al observar solo el boxplot, podríamos inferir que la distribución de los datos es normal, ya que el 50% de los datos se encuentra en el centro, la mediana está en el centro del cuadrado y el valor máximo y mínimo están a la misma distancia que los cuartiles. Sin embargo, al realizar el histograma de los datos, comprobamos que no se trata de la distribución que inicialmente pensábamos. No obstante, en el tercer gráfico, podemos afirmar que existe una correlación lineal positiva entre las ventas y el presupuesto destinado a la televisión. Finalmente, en el cuarto gráfico, podemos corroborar que la recta de regresión se ajusta a nuestras expectativas.

Después de estos gráficos, tenemos el de los intervalos de confianza para los valores medios y las predicciones de la variable de respuesta. Podemos observar que a medida que los valores crecen, el modelo ya no se ajusta de manera consistente, ya que algunos datos en la muestra se encuentran fuera de los intervalos de confianza. Si observamos el gráfico de dispersión que muestra la relación entre las variables, podemos notar que si trazáramos dos líneas rectas que encerraran todos los puntos, estas líneas no tendrían la misma pendiente y tendrían forma de cono. Esto indica que a medida que los valores del modelo aumentan, se separan más entre sí, lo que sugiere que el modelo no se ajusta adecuadamente para valores altos.

Por otro lado, los gráficos de los errores muestran un error máximo aproximado de 8, como se puede apreciar en el gráfico de líneas. Al calcular el promedio de los errores, obtenemos un valor de 2.54, que es relativamente bajo. Esto podría indicar que, a pesar de la falta de ajuste en los datos más grandes, el modelo sigue generando resultados precisos para los demás valores. La distribución de los errores muestra un sesgo hacia la derecha, y en el gráfico qq, los residuos intermedios del modelo se ajustan más a una distribución normal.

Nuestros coeficientes beta son la base para crear nuestra línea de regresión. Con un valor bajo de beta 1, indicamos que a medida que nuestra variable predictora aumenta, la variable de respuesta también lo hace, pero en una proporción mucho menor. La varianza residual es de 10, y tenemos un coeficiente de variación de 2, lo que sugiere que no hay una gran variabilidad relativa en comparación con nuestra media. El intervalo de confianza de beta 1 nos informa sobre el intervalo en el que se encuentra beta 1 con un nivel de significancia alpha. Como podemos observar, este intervalo no incluye el valor cero, lo que nos permite concluir con mayor confianza que rechazamos la hipótesis nula, indicando que beta 1 es diferente de cero.

```{r}
linealmodel(radio, sales, 0.05)
```


Con respecto a nuestros datos del nuevo modelo con "radio" como variable predictora, podemos observar en el boxplot que los datos están sesgados hacia la izquierda. El histograma también muestra una concentración mayor de datos en el lado izquierdo. Sin embargo, no se asemejan a una distribución conocida. En comparación con el modelo anterior, notamos que en este caso los datos están más dispersos, incluso con algunos valores atípicos en la relación. Al graficar la línea de regresión, podemos observar que en esta ocasión los puntos están más alejados de la línea, lo que sugiere un promedio de errores mayor que en el modelo anterior.

En cuanto a los intervalos de confianza, podemos observar que, en su mayoría, contienen los datos, excepto por algunos valores atípicos del modelo. Sin embargo, estos intervalos parecen ser más amplios que en el modelo anterior, ya que los datos se alejan más de la línea de regresión. En los gráficos de errores, notamos que los errores están más alejados en la parte inferior, mientras que en la parte superior de la línea, observamos un comportamiento de errores similar al del modelo anterior. En este caso, el histograma de errores también muestra un sesgo hacia la derecha, y en lo que respecta al ajuste a una distribución normal, los errores tienden a aproximarse más a una normal a medida que aumentan los presupuestos.

En este caso, nuestro valor de beta 1 es más alto, lo que indica que un aumento en la variable predictora tiene un impacto mucho mayor en los resultados de nuestra variable de respuesta. Sin embargo, también notamos una varianza mayor, ya que los datos están más dispersos entre sí, casi el doble que en el modelo anterior. Del mismo modo, el coeficiente de variación indica una alta variabilidad relativa en comparación con la media. El intervalo de confianza para beta 1 se sitúa entre 0.16 y 0.25 con un nivel de significancia alpha. Esto, junto con el valor p, nos lleva a rechazar la hipótesis nula que sugiere que beta 1 podría ser igual a cero. Como resultado, los errores son mayores, con un promedio de 3.32, aunque se esperaba que fueran mayores dada la forma de la gráfica y la aproximación de la línea.


```{r}
linealmodel(newsp, sales, 0.05)
```


En relación a nuestro último modelo, donde la variable predictora corresponde a los gastos publicitarios en periódicos, podemos observar dos outliers notables en el box plot que están muy alejados de los demás datos. Además, notamos que los datos están sesgados hacia la izquierda, y esto se confirma en el histograma, donde la mayoría de los presupuestos publicitarios son bajos para este tipo de medio. En este caso, se evidencia una mayor variabilidad en los datos, ya que los puntos están más dispersos que en los modelos anteriores, incluso más dispersos que en los modelos previos. Esto sugiere que este modelo probablemente tendrá errores más altos debido a la distancia entre los puntos y la línea de regresión. Los outliers que observamos indican que algunos gastos publicitarios son significativamente mayores de lo que generalmente se observa.

En cuanto a los intervalos de confianza, notamos que estos intervalos aún se ajustan a los datos en su mayoría, pero dejan algunos valores superiores fuera de los intervalos, como habíamos previsto. Los errores son bastante altos, llegando a superar los 10, y el promedio de errores es de 4.14, que es el error promedio máximo entre los tres modelos. El histograma de estos errores muestra un sesgo hacia la izquierda, y al observar el gráfico qq, se confirma que este modelo es el que menos se ajusta a una distribución normal.

Como en los casos anteriores, la varianza de este modelo es la más alta, lo que sugiere que los datos no dependen mucho del modelo y se ajustan de manera deficiente a la línea de regresión. La variación promedio relativa con respecto a la media es también bastante alta, lo que indica una baja confiabilidad en el modelo. El valor de beta 1 es pequeño, lo que significa que la variable de respuesta no cambia significativamente a medida que aumenta la variable predictora. Además, el valor p nos lleva a rechazar la hipótesis nula, lo que indica que beta 1 es diferente de cero.