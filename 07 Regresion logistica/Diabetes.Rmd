---
title: "Diabetes"
author: "Agustin Riquelme y Heriberto Espino"
date: "2023-08-30"
output: 
  html_document:
    theme: paper
---
```{r}
library(ISLR2)
library(tidyverse)
library(ggplot2)
library(MASS)
library(msm)
library(msmtools)
library(readr)
library(vcd)
library(PerformanceAnalytics)

data <- read_csv("C:/Users/herie/OneDrive/Documentos/GitHub/Econometria l/DataFrames/diabetes.csv")
head(data)
attach(data)
```

### 1. Construcción del modelo


Se construye un modelo para regresión logística.
```{r}
modlog <- glm(Outcome ~ ., 
              data = data, 
              family = "binomial")
summary(modlog)

```

###. 2. Introducción

El Conjunto de Datos de Diabetes, originalmente recopilado por el Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales y obtendo de  https://www.kaggle.com/datasets/mathchi/diabetes-data-set. Es un conjunto que se compone de variables médicas predictivas y una variable objetivo, “Outcome”. Las variables predictoras incluyen el número de embarazos que la paciente ha tenido, su IMC, nivel de insulina, edad y más.
El objetivo de este conjunto de datos es predecir si un paciente tiene diabetes, basándose en ciertas mediciones diagnósticas incluidas en el conjunto de datos. En particular, todos los pacientes aquí son mujeres de al menos 21 años de origen indio Pima.

Contenido del Conjunto de Datos
Este conjunto de datos presenta información específica sobre pacientes.
1.	Pregnancies (Embarazos): Número de veces que la paciente ha estado embarazada.
2.	Glucose (Glucosa): Concentración de glucosa en plasma 2 horas después de un examen de tolerancia a la glucosa oral.
3.	BloodPressure (Presión Arterial): Presión arterial diastólica en milímetros de mercurio (mm Hg).
4.	SkinThickness (Grosor del Pliegue Cutáneo): Grosor del pliegue cutáneo del tríceps en milímetros (mm).
5.	Insulin (Insulina): Nivel de insulina en suero 2 horas después de un examen (en unidades por mililitro - mu U/ml).
6.	BMI (Índice de Masa Corporal): Índice de masa corporal, calculado como el peso en kilogramos dividido por la altura en metros al cuadrado (kg/(m^2)).
7.	DiabetesPedigreeFunction (Función de Pedigrí de Diabetes): Función que representa la probabilidad de tener diabetes según el historial familiar.
8.	Age (Edad): Edad de la paciente en años.
9.	Outcome (Resultado): Variable cualitativa que indica si la paciente tiene diabetes (1) o no (0).


### 3. Gráficos

A continuación se presentan los gráficos de nuestro conjunto, junto con gráficos que relacionan las variables con nuestra variable predictora.
```{r}

chart.Correlation(data[ , -9])

ggplot(data, mapping = aes(x=factor(Outcome),y= Pregnancies,fill=factor(Outcome)))+
  geom_boxplot()+
  stat_boxplot(geom = "errorbar",width=0.2)

ggplot(data, mapping = aes(x=factor(Outcome),y= Glucose,fill=factor(Outcome)))+
  geom_boxplot()+
  stat_boxplot(geom = "errorbar",width=0.2)

ggplot(data, mapping = aes(x=factor(Outcome),y= BloodPressure,fill=factor(Outcome)))+
  geom_boxplot()+
  stat_boxplot(geom = "errorbar",width=0.2)

ggplot(data, mapping = aes(x=factor(Outcome),y= SkinThickness,fill=factor(Outcome)))+
  geom_boxplot()+
  stat_boxplot(geom = "errorbar",width=0.2)

ggplot(data, mapping = aes(x=factor(Outcome),y= Insulin,fill=factor(Outcome)))+
  geom_boxplot()+
  stat_boxplot(geom = "errorbar",width=0.2)

ggplot(data, mapping = aes(x=factor(Outcome),y= BMI,fill=factor(Outcome)))+
  geom_boxplot()+
  stat_boxplot(geom = "errorbar",width=0.2)

ggplot(data, mapping = aes(x=factor(Outcome),y= DiabetesPedigreeFunction,fill=factor(Outcome)))+
  geom_boxplot()+
  stat_boxplot(geom = "errorbar",width=0.2)

ggplot(data, mapping = aes(x=factor(Outcome),y=Age,fill=factor(Outcome)))+
  geom_boxplot()+
  stat_boxplot(geom = "errorbar",width=0.2)

```


### 4. Mejor modelo

Se eliminan las variables poco significativas del modelo completo.

```{r}
modlog <- glm(Outcome ~ . - SkinThickness - Insulin - Age - BloodPressure, 
              data = data, 
              family = "binomial")
summary(modlog)

```

### 5. Construccion de datatrain y datatest

Se dividirá el conjunto en un 80% para el data_train y en 20% para el data_test.
```{r}
split_dummy <- sample(c(rep(0, 0.8 * nrow(data)), rep(1, 1 + 0.2 * nrow(data))))
table(split_dummy)

data_train <- data[split_dummy == 0, ]
data_test <- data[split_dummy == 1, ]

Outcometest <- data_test$Outcome
```


### 6. Ajuste de modelo logistico con datatrain

Se construye el modelo con la base del data_train.
```{r}
glmtrain <- glm(Outcome ~ . - SkinThickness - Insulin - Age - BloodPressure, 
                data = data_train, 
                family = "binomial")
summary(glmtrain)

```



###  7. Construcción de glmprobs

Se construyen las probabilidades, en caso que sea mayor que 5 se considera "Up"y menor que 0.5 "Down".
```{r}
glmprobst <- predict(glmtrain, data_test, type = "response")
glmpredt <- rep("Down", nrow(data_test))
glmpredt[glmprobst > 0.5] = "Up"

```

### 8. Matriz de confusión

Se generará la matriz de confusión.

```{r}

tablepred <- table(glmpredt, Outcometest)
tablepred

mosaic(tablepred,gp=gpar(fill=matrix(c("#588c7e", "#c83349", "#c83349", "#588c7e"),2,2)))

```


###  9. Métricas de la matriz de confusión.

Se conseguiran las métricas de la matriz de confusión.

```{r}
tableper <- tablepred / (length(Outcometest))*100
round(tableper, 2)

tn <- tableper[1,1]
fn <- tableper[1,2]
fp <- tableper[2,1]
tp <- tableper[2,2]

# Accuracy: cantidad de predicciones positivas que fueron correctas.
accuracy <- tp + tn
round(accuracy, 2)

# Precision: porcentaje de casos positivos detectados.
precision <- tp / (tp + fp) * 100
round(precision, 2)


# La sensibilidad (o recall) representa la tasa de verdaderos positivos (True Positive Rate) ó TP. Es la proporción entre los casos positivos bien clasificados por el modelo, respecto al total de positivos. Para calcularlo en este caso:
sensibilidad <-  tp / (tp + fn) * 100
round(sensibilidad, 2)

# F1
f1 <- (2 * precision * sensibilidad) / (precision + sensibilidad)
round(f1, 2)

# Especificidad
especificidad <-tn / (tn + fp) * 100
round(especificidad, 2)

# Tasa de falsos positivos: Es similar a la precisión, pero se calcula considerando la proporción de 
# verdaderos positivos sobre todas las instancias predichas como positivas (TP / (TP + FP)) 
tfp <- tp / ( tp + fp ) * 100
round(tfp, 2)

# Tasa de falsos negativos: Mide la proporción de verdaderos negativos sobre todas las 
# instancias predichas como negativas (TN / (TN + FN)).
tfn <- tn / (tn + fn) * 100
round(tfn, 2)
```

### 10. Interpretación de las métricas.

Es importante mencionar que las métricas varían porque el data_train es random cada vez que se ejecuta, en este caso: 
Accuracy (Precisión): La precisión es la medida de la cantidad de predicciones positivas que fueron correctas en relación con el total de predicciones. En este caso, la precisión es del 80.52%, lo que significa que el 80.52% de las predicciones realizadas por el modelo fueron correctas.

Precision (Precisión): La precisión es el porcentaje de casos positivos detectados correctamente sobre el total de casos positivos predichos por el modelo. En este caso, la precisión es del 75.76%, lo que significa que el 75.76% de las instancias que el modelo predijo como positivas fueron realmente positivas.

Sensibilidad (Recall o True Positive Rate): La sensibilidad representa la proporción de casos positivos correctamente clasificados por el modelo en relación con el total de casos positivos reales. En este caso, la sensibilidad es del 53.19%, lo que indica que el modelo identificó correctamente el 53.19% de todos los casos positivos disponibles.

F1 Score: El F1 Score es la media armónica de precisión y sensibilidad. En este caso, el F1 Score es del 62.5%, lo que proporciona una medida equilibrada entre precisión y sensibilidad.

Especificidad: La especificidad es la proporción de casos negativos correctamente clasificados por el modelo en relación con el total de casos negativos reales. En este caso, la especificidad es del 92.52%, lo que indica que el modelo identificó correctamente el 92.52% de todos los casos negativos disponibles.

Tasa de Falsos Positivos (TFP): La tasa de falsos positivos mide la proporción de instancias que fueron incorrectamente clasificadas como positivas sobre el total de instancias predichas como positivas. En este caso, la tasa de falsos positivos es del 75.76%.

Tasa de Falsos Negativos (TFN): La tasa de falsos negativos mide la proporción de instancias que fueron incorrectamente clasificadas como negativas sobre el total de instancias predichas como negativas. En este caso, la tasa de falsos negativos es del 81.82%.

Como conlusión, el modelo presenta las siguientes características:
Precision (Precisión): 75.76%
Sensibilidad (Recall): 53.19%
Especificidad: 92.52%
Tasa de Falsos Positivos (TFP): 75.76%
Tasa de Falsos Negativos (TFN): 81.82%
Es decir, tiene una precisión relativamente buena (75.76%) y una alta especificidad (92.52%), lo que significa que es bueno para predecir correctamente las instancias negativas.

Sin embargo, la sensibilidad del modelo es relativamente baja (53.19%), lo que indica que el modelo no identifica correctamente una proporción significativa de casos positivos reales, es igual echar un volado que usar el modelo en este caso. Además, las tasas de falsos positivos y falsos negativos son bastante altas (ambas alrededor del 75-82%), o sea que el modelo está cometiendo errores al clasificar tanto instancias positivas como negativas.    
