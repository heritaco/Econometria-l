---
title: "Fastfood"
author: "Agustin Riquelme y Heriberto Espino"
date: "2023-08-30"
output: 
  html_document:
    theme: paper
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(readr)
library(tidyverse)
library(ggplot2)
library(lmtest)
library(nortest)
```

# I Introducción

La base de datos fastfood, obtenida de https://www.openintro.org/data/index.php?data=fastfood,  nos proporciona una detallada visión de las características nutricionales de 515 alimentos vendidos en cadenas de comida rapida. Cada observación en esta base es de alimento compuesto por 17 variables:

* Restaurante (restaurant): Identifica al restaurante del cual proviene la comida.

* Artículo (item): Indica el nombre específico del alimento.

* Calorías (calories): Número total de calorías en el alimento.

* Calorías de Grasa (cal_fat): Cantidad de calorías provenientes de grasas en el alimento.

* Grasa Total (total_fat): Cantidad total de grasa en el alimento.

* Grasa Saturada (sat_fat): Cantidad de grasas saturadas presentes en el alimento.

* Grasa Trans (trans_fat): Cantidad de grasas trans en el alimento.

* Colesterol (cholesterol): Cantidad de colesterol presente en el alimento.

* Sodio (sodium): Cantidad de sodio en miligramos en el alimento.

* Carbohidratos Totales (total_carb): Cantidad total de carbohidratos en el alimento.

* Fibra (fiber): Cantidad de fibra dietética presente en el alimento.

* Azúcar (sugar): Cantidad de azúcar en el alimento.

* Proteína (protein): Cantidad de proteína en el alimento.

* Vitamina A (vit_a): Cantidad de vitamina A en el alimento.

* Vitamina C (vit_c): Cantidad de vitamina C en el alimento.

* Calcio (calcium): Cantidad de calcio en el alimento.

* Ensalada (salad): Esta variable binaria, indica si el artículo es una ensalada (1) o no (0).

Para hacer nuestra regresión eliminaremos las variables categoricas _restaurant, item y salad_. La variable de respuesta que ocuparemos para los siguientes modelos será la variable carbohidratos.

```{r, echo=FALSE, warning=FALSE}

dir_path <- "C:/Users/herie/OneDrive/Documentos/GitHub/Econometria l/DataFrames/"
fastfood <- read_csv(paste0(dir_path, "fastfood.csv"))

fastf <- fastfood[, !(names(fastfood) %in% c('restaurant', 'item', 'salad'))]

fastf <- na.omit(fastf)
colnames(fastf)
```

# II Gráficos

Se presentrán los gráficos que relacionan a la variable predictora, carbohidratos, con las variables respuesta.

```{r, echo=FALSE, warning=FALSE}
ggplot(fastf, aes(x = calories, y = total_carb)) +
  geom_point(size = 2, shape = 1, color = "#770011", alpha = 0.8) +
  geom_text(aes(label = paste("Correlación =", round(cor(fastf$calories, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
  theme_minimal()

ggplot(fastf, aes(x=cal_fat, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
  geom_text(aes(label = paste("Correlación =", round(cor(fastf$cal_fat, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=total_fat, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
  geom_text(aes(label = paste("Correlación =", round(cor(fastf$total_fat, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=sat_fat, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
  geom_text(aes(label = paste("Correlación =", round(cor(fastf$sat_fat, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=trans_fat, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
  geom_text(aes(label = paste("Correlación =", round(cor(fastf$trans_fat, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=cholesterol, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
  geom_text(aes(label = paste("Correlación =", round(cor(fastf$cholesterol, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=sodium, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
  geom_text(aes(label = paste("Correlación =", round(cor(fastf$sodium, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=fiber, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
  geom_text(aes(label = paste("Correlación =", round(cor(fastf$fiber, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=sugar, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
    geom_text(aes(label = paste("Correlación =", round(cor(fastf$sugar, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=protein, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
    geom_text(aes(label = paste("Correlación =", round(cor(fastf$protein, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=vit_a, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
    geom_text(aes(label = paste("Correlación =", round(cor(fastf$vit_a, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=vit_c, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
    geom_text(aes(label = paste("Correlación =", round(cor(fastf$vit_c, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()

ggplot(fastf, aes(x=calcium, y= total_carb)) +
    geom_point(size=2, shape=1, color = "#770011", alpha = 0.8)+
    geom_text(aes(label = paste("Correlación =", round(cor(fastf$calcium, fastf$total_carb), 4))),
            x = Inf, y = -Inf, hjust = 1, vjust = 0, size = 4, color = "darkblue") +
    theme_minimal()
```


## III Mejor modelo de regresión lineal multiple

Para el mejor modelo de regresión multiple, se usará la función step y el modelo stepwise, el cuál realiza tanto el forward como el backward, con este podremos obtener el modelo de regresión múltiple que nos da los mejores resultados

```{r, echo=FALSE}
modelovacio <- lm(total_carb ~ 1 , data = fastf)
modelocompleto <- lm(total_carb ~ ., data = fastf)
modelomultiple <- step(modelovacio,scope = list(lower=modelovacio,upper=modelocompleto),direction = "both", trace = 0)
summary(modelomultiple)
```

* Como podemos observar, de las 13 variables que tenemos, sólo 11 resultaron de ayuda para la creación del mejor modelo a pesar de que algunas variables no eran significativas. Y como podemos observar, nuestro $B_0$ sí es significativo así como otros 8 betas más. Los otros a pesar de no ser significativos en el modelo, aportan a que sea mejor o de confianza. Tenemos un error bajo de 8.24 y además podemos observar que este modelo explica el 91.39% de las observaciones de nuestra base.

* Como prueba general para el modelo, podemos concluir que es significativo al tener un p valor más bajo que 0.05 (2.2e-16).

* Y como prueba individual, las variables que tienen un p-valor mayor a 0.05 serán descartadas, porque no hay evidencia suficiente para afirmar que esas variables son significativas para el modelo, en este caso son la variable _sodium, trans_fat y protein_.

```{r, echo=FALSE}
modelovacio <- lm(total_carb ~ 1 , data = fastf)
modelocompleto <- lm(total_carb ~ . - sodium - trans_fat - protein, data = fastf)
modelomultiple <- step(modelovacio,scope = list(lower=modelovacio,upper=modelocompleto),direction = "both", trace = 0)
summary(modelomultiple)
```



Pasaron de ser 11 variables predictoras a solo ser 9, al eliminar 3 y sumarse la variable _sat_fat_.

* Como prueba general para el modelo, se plantea el siguiente contraste de hipótesis. _H0: β1 = β2 = ··· = βk = 0 vs H1: Al menos una es diferente de 0_, podemos concluir que es significativo al tener un p-valor  menor que _α = 0.05_, 2.2e-16.

* En la prueba individual, nuestro contraste de hipotesis es \( HO: \beta_i = 0 \)  _vs_  \( H1: \beta_i \neq 0 \). Todas las variables son significativas. Las variables más significativas para el modelo son _calories_, _cholesterol_ y _sugar_ con un p-value < 2e-16.

* Es un buen modelo, su R-ajustado es de 90.73% y una desviación estándar, _s_, de 8.392.

```{r echo = FALSE}
plot(modelomultiple, col = "#110088", pch = 1, main = "Residuos del modelo llineal múltiple")
```

```{r echo=FALSE}
shapiro.test(modelomultiple$residuals)
```

```{r echo=FALSE}
dwtest(modelomultiple)
```

* Al realizar el análisis de residuales podemos observar que los residuos no se comportan normalmente al tener un p valor menor que 0.05. 

* En su correlación, por el test de Durbin-Watson, concluimos que puede haber una correlación positiva, el DW es menor que dos y su p-valor es muy bajo, por lo que es confiable.  

## IV Modelo con interacción

Para el caso de modelo de interacción, realizaremos un modelo lineal donde las variables tengan interacción entre sí, el mejor modelo encontrado fue el siguiente:


```{r, echo=FALSE}
modelo_con_interaccion <- lm(total_carb ~ calories*total_fat + calories*sugar + sugar*total_fat + vit_a + fiber, data = fastf)

summary(modelo_con_interaccion)
```

* La prueba general es buena, se plantea el siguiente contraste de hipótesis. _H0: β1 = β2 = ··· = βk = 0 vs H1: Al menos una es diferente de 0_, tiene un p-value: < 2.2e-16, es significativo.

* En la prueba individual, nuestro contraste de hipotesis es \( HO: \beta_i = 0 \)  _vs_  \( H1: \beta_i \neq 0 \). Todas las variables son significativas a un nivel de 0.05. Las variables más significativas para el modelo son _calories_ y _fiber_ con un p-value < 2e-16.

* Es un buen modelo, su R-ajustado es de 86.78% y una desviación estándar, _s_, de 10.02.

```{r echo=FALSE}
plot(modelo_con_interaccion, col = "#110088", pch = 1, main = "Residuos del modelo con interacción")
```

```{r echo=FALSE}
shapiro.test(modelo_con_interaccion$residuals)
```

```{r echo=FALSE}
dwtest(modelo_con_interaccion)
```

* Al realizar el análisis de residuales podemos observar que los residuos no se comportan normalmente al tener un p-valor de 3.073e-14, menor que 0.05. 

* En su correlación, por el test de Durbin-Watson, concluimos que puede haber una corrleación positiva, el DW es menor que 2 y su p-valor es muy bajo, 8.734e-13, por lo que es confiable. 

## V Modelo cuadrático completo

```{r echo=FALSE}
modcuam <- lm(total_carb ~ calories + sat_fat + calories*sat_fat + I(calories^2)+I(sat_fat^2), data=fastf)

summary(modcuam)
```

* La prueba general es buena, se plantea el siguiente contraste de hipótesis. _H0: β1 = β2 = ··· = βk = 0 vs H1: Al menos una es diferente de 0_, tiene un p-value: < 2.2e-16, es significativo.

* En la prueba individual, nuestro contraste de hipotesis es \( HO: \beta_i = 0 \)  _vs_  \( H1: \beta_i \neq 0 \). La única variable que es no significativa a un 0.05 es _sat_fat^2_. La variable más significativa para el modelo es _calories_ con un p-value < 2e-16.

* Tiene un R-ajustado es de 74.15% y una desviación estándar, _s_, de 14.01.

```{r echo=FALSE}
plot(modcuam, col = "#110088", pch = 1, main = "Residuos del modelo cuadrático completo")
```

```{r echo=FALSE}
shapiro.test(modcuam$residuals)
```

```{r echo=FALSE}
dwtest(modcuam)
```


* Al realizar el análisis de residuales podemos observar que los residuos no se comportan normalmente al tener un p-valor de 6.763e-08, menor que 0.05. 

* En su correlación, por el test de Durbin-Watson, concluimos que hay una corrleación positiva, el DW es menor que 1 y su p-valor es menor que 2.2e-16, por lo que es significativo.

## VI Modelos extra

Ees casi un modelo cuadrático completo de 3 variables, pero se elimino la interacción donde participan las 3 variables.

```{r echo=FALSE}
m1 <- lm(total_carb ~ calories*total_fat + protein*total_fat + calories*protein + I(calories^2)+I(total_fat^2)+I(protein^2), data=fastf)

summary(m1)
```

```{r, echo=FALSE, warning=FALSE}
plot(m1, col = "#110088", pch = 1, main = "Residuos del modelo 1")
```

```{r echo=FALSE}
shapiro.test(m1$residuals)
```

```{r echo=FALSE}
dwtest(m1)
```

Para este caso se realizó un modelo cuadrático "completo", donde, como en modelos anteriores, el número total de carbohidratos sería la variable de respuesta y las demás las predictoras, en este caso obtenemos lo siguiente:

```{r echo=FALSE}
m2 <- lm(total_carb ~ . + I(calories^2)+I(cal_fat^2)+I(total_fat^2)+I(sat_fat^2)+I(trans_fat^2)+I(cholesterol^2)+I(sodium^2)+I(fiber^2)+I(sugar^2)+I(protein^2)+I(vit_a^2)+I(vit_c^2)+I(calcium^2) + calories*total_fat*sugar, data=fastf)

summary(m2)
```

De donde podemos observar 10 variables predictoras que no resultaron significativas para el modelo: 
_total_fat, sat_fat, trans_fat, sodium, vit_a, I(total_fat^2)  , I(trans_fat^2), I(sodium^2), I(fiber^2), I(vit_a^2), calories*total_fat*sugar_, serán descartadas, se seleccionarán las variables significativas para el modelo para realizar las interacciones entre sí y que no resulte tan pesado para explicar, para ello, las variables que tienen un valor más significativo son calorías y colesterol. Así que nuestro nuevo modelo será con estas variables

```{r, echo=FALSE, warning=FALSE}
m2 <- lm(total_carb ~ calories + cal_fat + cholesterol + fiber + sugar + protein + vit_c + calcium + I(cal_fat^2) + I(calories^2)  + I(sat_fat^2) +I(cholesterol^2) + I(sugar^2)  + I(protein^2) + I(vit_c^2) + calories*total_fat + calories * sugar + total_fat * sugar, data=fastf)
summary(m2)
```

```{r, echo=FALSE, warning=FALSE}
plot(m2, col = "#110088", pch = 1, main = "Residuos del modelo 2")
```

```{r echo=FALSE}
shapiro.test(m2$residuals)
```

```{r echo=FALSE}
dwtest(m2)
```

## VII Conclusión

Para determinar cuál es el mejor modelo, o cuál genera el mejor ajuste, será necesario recurrir al criterio de Aikake. El mejor modelo será aquel que tenga el valor más bajo. Los valores para cada uno de los tres modelos son los siguientes:

```{r echo=FALSE}
cat("AIC Modelo cuadrático Lineal Múltiple: ", AIC(modelomultiple))
cat("AIC modelo con interacción: ", AIC(modelo_con_interaccion))
cat("AIC Modelo caudrático completo: ", AIC(modcuam))
cat("AIC Modelo extra 1: ", AIC(m1))
cat("AIC Modelo extra 2: ", AIC(m2))
```

Entre los 3 primeros modelos, podemos observar que el modelo que tiene el valor de Aikake más bajo es el primer modelo, el modelo de regresión lineal múltiple. Contando los modelos extras, el mejor modelo es el modelo extra 2.